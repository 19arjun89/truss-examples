# Llama 3.1 405B Instruct

This is an implementation of Llama 3.1 405B for deployment on Baseten.

- VLLM for faster inference
- FP8 model weights
- Runs on an 8xH100 instance

Baseten offers private, secure deployments for LLMs like Llama 3.1 405B, including deployments to your own VPC.
To deploy this model on Baseten, contact us at [support@baseten.co](support@baseten.co).
