environment_variables: {}
external_package_dirs: []
model_metadata: {}
model_name: Llama 3 8B Instruct
python_version: py310
model_cache:
  - repo_id: meta-llama/Meta-Llama-3-8B-Instruct
requirements:
  - accelerate
  - einops
  - transformers
  - torch
resources:
  accelerator: A100
  use_gpu: true
secrets:
  hf_access_token: "your-hf-access-token"
system_packages: []
